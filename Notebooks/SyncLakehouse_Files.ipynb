{"cells":[{"cell_type":"markdown","source":["This notebook copies the folders and files from a lakehouse to another based on a watermark.\n","It considers the timestamp in which the folder or the files has been created in the source.\n","If the watermark is greater or equal than the last modify date for the folder/file, this will be copied on the targed.\n","If the watermark is lower than the last modify date for the folder/file, this will be ignored.\n","\n","<u>DO NOT USE IT TO COPY DELTA TABLES</u>"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"66d09be5-b87f-474c-89e8-15e9dc9fdd10"},{"cell_type":"markdown","source":["**Parameters**\n","workspace_source : String - Name of the sourc workspace </br>\n","workspace_target : String - Name of the target workspace </br>  \n","lakehouse_source : String - Name of the source lakehouse </br> \n","lakehouse_target = String - Name of the target lakehouse </br>\n","source_root = String - Initial folder to start from </br>\n","target_root = String - Initial target folder to start from </br>\n","overwritetarget = Boolean </br> \n","    - True: In case the folder/file already exists in the target will be overwritten </br>\n","    - False: In case the folder/file already exists in the target will be skipped </br>\n","datetime_str : Timestamp - watermark for the new files </br>\n","\n","\n","**Limitation**\n","Shortcuts in source lakehouse will be considered as regular folders and their content will be copied in the target lakehouse using a Onelake folder."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5f51eec2-2525-42e0-8f4d-8a39580ec9a9"},{"cell_type":"code","source":["workspace_source = 'softdeletetest'\n","workspace_target = 'testrestorenotebook'\n","lakehouse_source = 'mylakehouse' \n","lakehouse_target = 'targetlakehouse'\n","source_root = 'Files/monthly'\n","target_root = 'Files/'\n","overwritetarget = True\n","datetime_str = '2024-09-27 13:44:00'\n","\n","#do not change this\n","source = f'abfss://{workspace_source}@onelake.dfs.fabric.microsoft.com/{lakehouse_source}.Lakehouse/{source_root}'"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":62,"statement_ids":[62],"state":"finished","livy_statement_state":"available","session_id":"fc12947d-f5da-44a9-974d-479236bf29c9","normalized_state":"finished","queued_time":"2024-09-27T14:26:13.2644428Z","session_start_time":null,"execution_start_time":"2024-09-27T14:26:13.9363944Z","execution_finish_time":"2024-09-27T14:26:14.1818571Z","parent_msg_id":"a4433b72-a3f2-4dc4-bc3f-31744ade33ca"},"text/plain":"StatementMeta(, fc12947d-f5da-44a9-974d-479236bf29c9, 62, Finished, Available, Finished)"},"metadata":{}}],"execution_count":60,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e3d99269-ef5c-40dd-84dc-32f90e887d58"},{"cell_type":"markdown","source":["**copydata**\n","\n","This define the routine to copy the folders/files </br>\n","\n","Parameters:</br>\n","sourcepath : String - Source path of the folder/file </br>\n","targetpath : String - Target path for the folder/file </br>\n","recursive : Boolean - </br>\n","        1. True - Subfolders and files will be copied</br>\n","        2. False - Subfolders and files will not be considered</br>\n","overwrite : Boolean -  </br>\n","        1. True : Folder/File will be overwritten in case you run the process multiple time with the same watermark    </br>\n","        2. False : Folder/File will be skipped in case you run the process multiple time with the same watermark     </br>   \n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"80229738-f1fc-4097-8964-24fe327313ae"},{"cell_type":"code","source":["from notebookutils import mssparkutils\n","\n","def copydata(sourcepath='.', targetpath='.', recursive=True, overwrite=False):\n","    try:\n","        try:\n","            mssparkutils.fs.ls(targetpath)\n","            if overwrite:\n","                exists = f'overwrite={overwrite},{targetpath} already exists, sync will drop it'\n","                mssparkutils.fs.rm(targetpath, recursive)\n","            if not overwrite:\n","                exists = f'overwrite={overwrite},{targetpath} already exists, sync will skip it'\n","        except Exception as e:\n","            exists = f'{targetpath} does not exist, sync will create it'\n","        mssparkutils.fs.cp(sourcepath, targetpath, recursive)\n","        status = 'Completed'\n","    except Exception as e:\n","           status = f'Error during the copy: {str(e)}'\n","    return f'{exists} - {status}'"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":63,"statement_ids":[63],"state":"finished","livy_statement_state":"available","session_id":"fc12947d-f5da-44a9-974d-479236bf29c9","normalized_state":"finished","queued_time":"2024-09-27T14:26:13.3140512Z","session_start_time":null,"execution_start_time":"2024-09-27T14:26:14.6415176Z","execution_finish_time":"2024-09-27T14:26:14.9504478Z","parent_msg_id":"1abca159-9ed1-4411-896f-86d7e98ad8aa"},"text/plain":"StatementMeta(, fc12947d-f5da-44a9-974d-479236bf29c9, 63, Finished, Available, Finished)"},"metadata":{}}],"execution_count":61,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c7b4ddb2-2149-41f0-9084-7632f589f4aa"},{"cell_type":"markdown","source":["**SyncFilesFromFolder**\n","\n","This define the routine to identify folders and files that need to be copied </br>\n","root : String - Initial path to start the scan from"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8cb1cf6a-b515-4dc2-bed4-c5ce31d69234"},{"cell_type":"code","source":["from notebookutils import mssparkutils\n","from pyspark.sql.types import * #StructType, StructField\n","from datetime import datetime as D\n","from pyspark.sql.functions import from_unixtime, col, to_utc_timestamp\n","\n","def SyncFilesFromFolder(root = '.'):\n","\n","    dt = D.strptime(datetime_str, '%Y-%m-%d %H:%M:%S')\n","    unix_timestamp = int(dt.timestamp())\n","\n","    files = mssparkutils.fs.ls(root)\n","\n","    columns = StructType([\n","        StructField('executiontime', TimestampType(), True),\n","        StructField('file', StringType(), True),\n","        StructField('modifyTime', StringType(), True ),\n","        StructField('status', StringType(), True)\n","    ])\n","    \n","    file_details = []\n","    \n","    # Create an empty DataFrame with the specified schema\n","    new_files = spark.createDataFrame(file_details, schema=columns)\n","    for file in files:\n","       \n","        target = file.path.replace(workspace_source, workspace_target)\n","        target = target.replace(lakehouse_source, lakehouse_target)\n","\n","        if file.isDir and file.modifyTime/1000 < unix_timestamp:\n","            new_files = new_files.union(SyncFilesFromFolder(file.path))\n","        elif file.isDir and file.modifyTime/1000 >= unix_timestamp:   \n","            status=copydata(file.path, target, True, overwritetarget)\n","            new_row = (D.now(),file.path, file.modifyTime,status)\n","            file_details.append(new_row)\n","\n","        if not file.isDir and file.modifyTime/1000 >= unix_timestamp:\n","            status=copydata(file.path, target, False, overwritetarget)\n","            new_row = (D.now(), file.path, file.modifyTime, status)\n","            #new_row = (file.path, D.fromtimestamp(file.modifyTime / 1000,target_timezone).strftime('%Y-%m-%d %H:%M:%S'))\n","            file_details.append(new_row)\n","\n","    df = spark.createDataFrame(file_details, columns)\n","    new_files = new_files.union(df)\n","    del df\n","\n","    return new_files"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":64,"statement_ids":[64],"state":"finished","livy_statement_state":"available","session_id":"fc12947d-f5da-44a9-974d-479236bf29c9","normalized_state":"finished","queued_time":"2024-09-27T14:26:13.3488068Z","session_start_time":null,"execution_start_time":"2024-09-27T14:26:15.4551716Z","execution_finish_time":"2024-09-27T14:26:15.7036725Z","parent_msg_id":"b597007c-c2bd-4d19-bdce-e54b58b587b9"},"text/plain":"StatementMeta(, fc12947d-f5da-44a9-974d-479236bf29c9, 64, Finished, Available, Finished)"},"metadata":{}}],"execution_count":62,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8501192c-7a18-471d-adc1-30aaff9a0bf8"},{"cell_type":"markdown","source":["**Runs the process**\n","This cell runs the copy and save the detailed results in a temporary view "],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3e06e144-ea29-46d1-8beb-8e3b1f4bccff"},{"cell_type":"code","source":["df = SyncFilesFromFolder(source)\n","df.createOrReplaceTempView('Results')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":65,"statement_ids":[65],"state":"finished","livy_statement_state":"available","session_id":"fc12947d-f5da-44a9-974d-479236bf29c9","normalized_state":"finished","queued_time":"2024-09-27T14:26:13.4461881Z","session_start_time":null,"execution_start_time":"2024-09-27T14:26:16.1756601Z","execution_finish_time":"2024-09-27T14:26:24.2424259Z","parent_msg_id":"73b9d7d1-5922-48c8-b4a6-254e9c0ec7ba"},"text/plain":"StatementMeta(, fc12947d-f5da-44a9-974d-479236bf29c9, 65, Finished, Available, Finished)"},"metadata":{}}],"execution_count":63,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"77f59f1a-59f5-4e45-8264-36a70caea4f5"},{"cell_type":"markdown","source":["**Checking the outcome**\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b849f278-789e-4902-807e-77781a421b96"},{"cell_type":"code","source":["%%sql\n","SELECT *, cast(modifyTime/1000 as Timestamp) FROM Results"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":66,"statement_ids":[66],"state":"finished","livy_statement_state":"available","session_id":"fc12947d-f5da-44a9-974d-479236bf29c9","normalized_state":"finished","queued_time":"2024-09-27T14:26:13.4754756Z","session_start_time":null,"execution_start_time":"2024-09-27T14:26:24.6542967Z","execution_finish_time":"2024-09-27T14:26:34.5904144Z","parent_msg_id":"dc1386df-6a25-4291-ae98-38032b52ead8"},"text/plain":"StatementMeta(, fc12947d-f5da-44a9-974d-479236bf29c9, 66, Finished, Available, Finished)"},"metadata":{}},{"output_type":"execute_result","execution_count":64,"data":{"application/vnd.synapse.sparksql-result+json":{"schema":{"type":"struct","fields":[{"name":"executiontime","type":"timestamp","nullable":true,"metadata":{}},{"name":"file","type":"string","nullable":true,"metadata":{}},{"name":"modifyTime","type":"string","nullable":true,"metadata":{}},{"name":"status","type":"string","nullable":true,"metadata":{}},{"name":"CAST((modifyTime / 1000) AS TIMESTAMP)","type":"timestamp","nullable":true,"metadata":{"__autoGeneratedAlias":"true"}}]},"data":[["2024-09-27T14:26:20Z","abfss://softdeletetest@onelake.dfs.fabric.microsoft.com/mylakehouse.Lakehouse/Files/monthly/2023/03/TestUpload.parquet","1727444943692","overwrite=True,abfss://testrestorenotebook@onelake.dfs.fabric.microsoft.com/targetlakehouse.Lakehouse/Files/monthly/2023/03/TestUpload.parquet already exists, sync will drop it - Completed","2024-09-27T13:49:03Z"]]},"text/plain":"<Spark SQL result set with 1 rows and 5 fields>"},"metadata":{}}],"execution_count":64,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"sparksql","language_group":"synapse_pyspark"},"collapsed":false},"id":"08b825ce-d61f-47f4-a676-dc016e4a5dd9"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{}},"nbformat":4,"nbformat_minor":5}
